{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will add latent demand to the trips. It is assumed that the phenomenon of censored demand occurs when a station is empty for at least one hour. To recreate the information about the missing trips, new trips are added randomly based on the average behaviour during the same period at other days, but only when the station was not empty. The seed used for our study is 42. (supplement: there may have been a problem with the seed, so the simulation results could"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = pd.read_csv('../data/stations_aug.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the snapshots and trips data. The index is rounded to one hour to focus on periods of a full hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshots = pd.read_csv('../data/station_snapshot_aug.csv', usecols=['timestamp',\n",
    "                            'dock_group_title', 'available_bikes'], parse_dates=['timestamp'], index_col='timestamp')\n",
    "snapshots.index = snapshots.index.map(lambda x: x.round('H'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_set = pd.read_csv('../data/trips_08-2019.csv', usecols=['started_at', 'ended_at', 'start_station_name',\n",
    "                        'end_station_name', 'duration'], parse_dates=['started_at', 'ended_at'], index_col='started_at')\n",
    "trips_set.index = trips_set.index.map(lambda x: x.round('H'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset with the additional trips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_trips = pd.DataFrame(columns=['started_at',\n",
    "                        'ended_at',\n",
    "                        'duration',\n",
    "                        'start_station_name',\n",
    "                        'end_station_name'])\n",
    "new_trips.started_at = pd.to_datetime(new_trips.started_at)\n",
    "new_trips.ended_at = pd.to_datetime(new_trips.ended_at)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function determines the distribution of all possible destinations in the given dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transitions(ds):\n",
    "    destinations = ds.groupby('end_station_name')['end_station_name'].count().to_frame()\n",
    "    destinations = destinations.rename(columns={'end_station_name': 'count'})\n",
    "    destinations = destinations.reset_index()\n",
    "    destinations['prob'] = destinations['count'] / destinations['count'].sum()\n",
    "    return destinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function uses `get_transitions` to randomly pick a destination based on the returnd distribution. If it is unsuccessful with the dataset for `hour`, it will try again using the complete dataset, e.g. the overall destination distribution. If that also fails, it will return -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_end_station(hour, start_station):\n",
    "    prob = get_transitions(trips_set[(trips_set.start_station_name == start_station) & (trips_set.index.hour == hour)])\n",
    "    if len(prob) == 0:\n",
    "        prob = get_transitions(trips_set[(trips_set.start_station_name == start_station)])\n",
    "    if len(prob) == 0:\n",
    "        return -1\n",
    "    prob = np.random.choice(prob.end_station_name, p=prob.prob, size=1)\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will generate a new entry for the trips data. The journey will start at `start_station`. It uses the average behaviour in hour `hour` for the station `start_station`. If it is unsuccessfull, it will return an empty dictionary `{}` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trip(hour, start_station):\n",
    "    # choose starting time\n",
    "    started_at_hour = (h + (0.9 * np.random.rand()))\n",
    "    started_at_minute = int(round((started_at_hour - int(started_at_hour)) * 60, 0))\n",
    "    if started_at_minute >= 60:\n",
    "        started_at_minute = 59\n",
    "    started_at_hour = int(started_at_hour)\n",
    "    started_at = pd.Timestamp(year=d.year, month=d.month, day=d.day,\n",
    "                             hour=started_at_hour, minute=started_at_minute, second=0,\n",
    "                             microsecond=0)\n",
    "    # choose origin\n",
    "    start_station_name = start_station\n",
    "    # choose destination\n",
    "    end_station_name = select_end_station(h, start_station)\n",
    "    if end_station_name == -1:\n",
    "        return {}\n",
    "    else:\n",
    "        end_station_name = end_station_name[0]\n",
    "    # calculate duration\n",
    "    duration = trips_set[trips_set.start_station_name == start_station].groupby('end_station_name').duration.mean()\n",
    "    duration = duration[duration.index == end_station_name]\n",
    "    if len(duration) <= 0:\n",
    "        duration = trips_set.duration.mean()\n",
    "    else:\n",
    "        duration = duration.values[0]\n",
    "    # calculate ending time\n",
    "    ended_at = started_at + pd.to_timedelta(duration, unit='s')\n",
    "    return {\n",
    "        'started_at': started_at,\n",
    "        'ended_at': ended_at,\n",
    "        'duration': duration,\n",
    "        'start_station_name': start_station_name,\n",
    "        'end_station_name': end_station_name\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the actual algorithm, that generates the latent demand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for station in stations.station_name:\n",
    "    print('fill for station {0}'.format(station))\n",
    "    # get all the entries from the snapshots data where the current station was empty\n",
    "    station_empty = snapshots[(snapshots.dock_group_title == station) & (snapshots.available_bikes == 0)] \n",
    "    # pick only those entries where there was no trip in the trips data\n",
    "    station_empty = station_empty[~station_empty.index.isin(trips_set[trips_set.start_station_name == station].index)]\n",
    "    # repeat for all hours where the station was empty\n",
    "    for h in station_empty.index.drop_duplicates().hour:\n",
    "        # get average demand for that hour when the station was not empty\n",
    "        trips = trips_set[(trips_set.start_station_name == station)].resample('60Min').duration.count()\n",
    "        trips = trips.groupby(trips.index.hour).mean()\n",
    "        trips = trips[trips.index == h]\n",
    "        # determine the number of trips to generate as the rounded average\n",
    "        if len(trips) > 0:\n",
    "            n_trips = int(round(trips.values[0], 0))\n",
    "        else:\n",
    "            n_trips = 0\n",
    "        # loop through all the dates where the station was empty at the current hour\n",
    "        for d in station_empty[station_empty.index.hour == h].index.drop_duplicates().date:\n",
    "            # generate trips and append them to the new_trips dataframe\n",
    "            for i in np.arange(0, n_trips):\n",
    "                trip = generate_trip(h, station)\n",
    "                if len(trip) > 0:\n",
    "                    new_trips = new_trips.append(trip, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_trips.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the old trips data again and add the newly generated journeys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_trips = pd.read_csv('../data/trips_08-2019.csv', usecols=['started_at', 'ended_at', 'duration', 'start_station_name',\n",
    "                        'end_station_name'], parse_dates=['started_at', 'ended_at'], index_col='started_at')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_trips = new_trips.set_index(new_trips.started_at)\n",
    "old_trips = old_trips.append(new_trips, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "old_trips = old_trips.drop(columns=['started_at'])\n",
    "old_trips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_trips.to_csv('../data/trips_08-2019_latent_demand.csv', columns=['ended_at', 'duration', 'start_station_name',\n",
    "                        'end_station_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
